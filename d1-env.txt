把以下配置文件拷贝到
/home/hadoop/20171107/yourname 目录下
通过cat命令查看对应核心配置文件的参数

#Hadoop核心参数配置$HADOOP_HOME/etc/hadoop/
1、master 记录运行辅助namenode的机器列表 
2、slaves 记录运行datanode和tasktracker的机器列表 
3、hadoop-env.sh 记录脚本要用的环境变量，以运行hadoop 
4、core-site.xml hadoop core的配置项，例如hdfs和mapreduce常用的i/o设置等 
5、hdfs-site.xml hadoop守护进程的配置项，包括namenode、辅助namenode和datanode等 
6、mapred-site.xml mapreduce守护进程的配置项，包括jobtracker和tasktracker 
7、hadoop-metrics.properties 控制metrics在hadoop上如何发布的属性 
8、log4j.properties 系统日志文件、namenode审计日志、tasktracker子进程的任务日志的属性 
9 hive-site.xml 进行Hive的核心参数配置 $HIVE_HOME/conf
10 zoo.cfg ZOOKEEPER的配置参数 路径home/hadoop/bigdata/zk/conf
11 hbase-site.xml 进行HBASE的参数配置$HBASE_HOME/conf


#把hdfs集群中指定目录下的文件内容合并下载到本地指定文件内
hadoop fs -getmerge  /20171107/yourname/ /20171107/yourname/merge.txt